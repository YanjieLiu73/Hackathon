{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de48ce79-91f2-4f15-97db-6a9d94b154a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebdb5b1b-bb12-49a1-9a8d-c091d8ac3676",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv('Key_OpenAI')\n",
    "os.environ['SERPER_API_KEY'] = os.getenv('Key_Serper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd363638-7b2e-4968-9855-2ac0eb6d885b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateResult(finish_reason='stop', content='The capital of France is Paris.', usage=RequestUsage(prompt_tokens=15, completion_tokens=7), cached=False, logprobs=None)\n"
     ]
    }
   ],
   "source": [
    "from autogen_core.components.models import OpenAIChatCompletionClient, UserMessage\n",
    "\n",
    "# Create an OpenAI model client.\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o\",\n",
    "    # api_key=os.getenv['OPENAI_API_KEY'] # Optional if you have an OPENAI_API_KEY env variable set.\n",
    ")\n",
    "model_client_result = await model_client.create(\n",
    "    messages=[\n",
    "        UserMessage(content=\"What is the capital of France?\", source=\"user\"),\n",
    "    ]\n",
    ")\n",
    "print(model_client_result)  # \"Paris\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5833310d-6ef3-4ac8-96b3-8e722a8b504f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_client_result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3577eff2-0022-47d4-8659-f6abff2a4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from autogen_agentchat import EVENT_LOGGER_NAME\n",
    "from autogen_agentchat.agents import ToolUseAssistantAgent\n",
    "from autogen_agentchat.logging import ConsoleLogHandler\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core.base import CancellationToken\n",
    "from autogen_core.components.models import OpenAIChatCompletionClient\n",
    "from autogen_core.components.tools import FunctionTool\n",
    "\n",
    "logger = logging.getLogger(EVENT_LOGGER_NAME)\n",
    "logger.addHandler(ConsoleLogHandler())\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# Create an OpenAI model client.\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o\",\n",
    "    # api_key=\"sk-...\", # Optional if you have an OPENAI_API_KEY env variable set.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05783a5b-735c-41e6-bd65-7dc807a10c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreateResult(finish_reason='stop', content='The capital of France is Paris.', usage=RequestUsage(prompt_tokens=15, completion_tokens=7), cached=False, logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wp/6gm0gp7n5653wzt3d3527vsw0000gn/T/ipykernel_3876/281869091.py:1: RuntimeWarning: coroutine 'BaseOpenAIChatCompletionClient.create' was never awaited\n",
      "  model_client_result = await model_client.create(\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "model_client_result = await model_client.create(\n",
    "    messages=[\n",
    "        UserMessage(content=\"What is the capital of France?\", source=\"user\"),\n",
    "    ]\n",
    ")\n",
    "print(model_client_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8e19556-0856-4c90-a80c-43236b904db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wp/6gm0gp7n5653wzt3d3527vsw0000gn/T/ipykernel_3876/32951612.py:6: DeprecationWarning: ToolUseAssistantAgent is deprecated. Use AssistantAgent instead.\n",
      "  tool_use_agent = ToolUseAssistantAgent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(chat_message=TextMessage(source='tool_use_agent', model_usage=RequestUsage(prompt_tokens=74, completion_tokens=41), content='France is a large country with diverse climates, so weather conditions can vary significantly between regions. Could you please specify a particular city or region in France for which you would like to know the current weather?'), inner_messages=[])\n"
     ]
    }
   ],
   "source": [
    "async def get_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is 72 degrees and Sunny.\"\n",
    "\n",
    "get_weather_tool = FunctionTool(get_weather, description=\"Get the weather for a city\")\n",
    "\n",
    "tool_use_agent = ToolUseAssistantAgent(\n",
    "    \"tool_use_agent\",\n",
    "    system_message=\"You are a helpful assistant that solves tasks by only using your tools.\",\n",
    "    model_client=model_client,\n",
    "    registered_tools=[get_weather_tool],\n",
    ")\n",
    "\n",
    "tool_result = await tool_use_agent.on_messages(\n",
    "    messages=[\n",
    "        TextMessage(content=\"What is the weather right now in France?\", source=\"user\"),\n",
    "    ],\n",
    "    cancellation_token=CancellationToken(),\n",
    ")\n",
    "print(tool_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9ffc180-c420-49d4-becf-f641f36fc33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'France is a large country with diverse climates, so weather conditions can vary significantly between regions. Could you please specify a particular city or region in France for which you would like to know the current weather?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_result.chat_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48363743-d5c8-4ced-b72c-681e09279c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wp/6gm0gp7n5653wzt3d3527vsw0000gn/T/ipykernel_7718/3560099154.py:23: DeprecationWarning: CodingAssistantAgent is deprecated. Use AssistantAgent instead.\n",
      "  writing_assistant_agent = CodingAssistantAgent(\n",
      "/var/folders/wp/6gm0gp7n5653wzt3d3527vsw0000gn/T/ipykernel_7718/3560099154.py:36: DeprecationWarning: ToolUseAssistantAgent is deprecated. Use AssistantAgent instead.\n",
      "  tool_use_agent = ToolUseAssistantAgent(\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from autogen_agentchat import EVENT_LOGGER_NAME\n",
    "from autogen_agentchat.agents import CodingAssistantAgent, ToolUseAssistantAgent\n",
    "from autogen_agentchat.logging import ConsoleLogHandler\n",
    "from autogen_agentchat.task import MaxMessageTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat, SelectorGroupChat\n",
    "from autogen_core.components.models import OpenAIChatCompletionClient\n",
    "from autogen_core.components.tools import FunctionTool\n",
    "\n",
    "# Set up a log handler to print logs to the console.\n",
    "logger = logging.getLogger(EVENT_LOGGER_NAME)\n",
    "logger.addHandler(ConsoleLogHandler())\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# Create an OpenAI model client.\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o\",\n",
    "    # api_key=\"sk-...\", # Optional if you have an OPENAI_API_KEY env variable set.\n",
    ")\n",
    "\n",
    "writing_assistant_agent = CodingAssistantAgent(\n",
    "    name=\"writing_assistant_agent\",\n",
    "    system_message=\"You are a helpful assistant that solve tasks by generating text responses and code.\",\n",
    "    model_client=model_client,\n",
    ")\n",
    "\n",
    "\n",
    "async def get_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is 72 degrees and Sunny.\"\n",
    "\n",
    "\n",
    "get_weather_tool = FunctionTool(get_weather, description=\"Get the weather for a city\")\n",
    "\n",
    "tool_use_agent = ToolUseAssistantAgent(\n",
    "    \"tool_use_agent\",\n",
    "    system_message=\"You are a helpful assistant that solves tasks by only using your tools.\",\n",
    "    model_client=model_client,\n",
    "    registered_tools=[get_weather_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "313a0710-9844-4622-ba24-26c4eccf04d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:32.881251]:\u001b[0m\n",
      "\n",
      "Write a Haiku about the weather in Paris\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:32.881251]:\u001b[0m\n",
      "\n",
      "Write a Haiku about the weather in Paris\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:32.881251]:\u001b[0m\n",
      "\n",
      "Write a Haiku about the weather in Paris\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:32.881251]:\u001b[0m\n",
      "\n",
      "Write a Haiku about the weather in Paris\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:32.881251]:\u001b[0m\n",
      "\n",
      "Write a Haiku about the weather in Paris\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:32.881251]:\u001b[0m\n",
      "\n",
      "Write a Haiku about the weather in Paris\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:34.237212], tool_use_agent:\u001b[0m\n",
      "\n",
      "Sunny skies in view,  \n",
      "Paris basks in golden light,  \n",
      "Warm embrace of day.  \n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:34.237212], tool_use_agent:\u001b[0m\n",
      "\n",
      "Sunny skies in view,  \n",
      "Paris basks in golden light,  \n",
      "Warm embrace of day.  \n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:34.237212], tool_use_agent:\u001b[0m\n",
      "\n",
      "Sunny skies in view,  \n",
      "Paris basks in golden light,  \n",
      "Warm embrace of day.  \n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:34.237212], tool_use_agent:\u001b[0m\n",
      "\n",
      "Sunny skies in view,  \n",
      "Paris basks in golden light,  \n",
      "Warm embrace of day.  \n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:34.237212], tool_use_agent:\u001b[0m\n",
      "\n",
      "Sunny skies in view,  \n",
      "Paris basks in golden light,  \n",
      "Warm embrace of day.  \n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:34.237212], tool_use_agent:\u001b[0m\n",
      "\n",
      "Sunny skies in view,  \n",
      "Paris basks in golden light,  \n",
      "Warm embrace of day.  \n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:34.281390], Termination:\u001b[0m\n",
      "\n",
      "Maximum number of messages 2 reached, current message count: 2\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:34.281390], Termination:\u001b[0m\n",
      "\n",
      "Maximum number of messages 2 reached, current message count: 2\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:34.281390], Termination:\u001b[0m\n",
      "\n",
      "Maximum number of messages 2 reached, current message count: 2\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:34.281390], Termination:\u001b[0m\n",
      "\n",
      "Maximum number of messages 2 reached, current message count: 2\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:34.281390], Termination:\u001b[0m\n",
      "\n",
      "Maximum number of messages 2 reached, current message count: 2\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:07:34.281390], Termination:\u001b[0m\n",
      "\n",
      "Maximum number of messages 2 reached, current message count: 2"
     ]
    }
   ],
   "source": [
    "termination = MaxMessageTermination(max_messages=2)\n",
    "round_robin_team = RoundRobinGroupChat([tool_use_agent, writing_assistant_agent], termination_condition=termination)\n",
    "round_robin_team_result = await round_robin_team.run(\"Write a Haiku about the weather in Paris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb73baa1-b8f6-45b5-83f9-0fdcbedbcc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:06:09.823719]:\u001b[0m\n",
      "\n",
      "What is the weather in paris right now? Also write a haiku about it.\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:06:09.823719]:\u001b[0m\n",
      "\n",
      "What is the weather in paris right now? Also write a haiku about it.\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:06:09.823719]:\u001b[0m\n",
      "\n",
      "What is the weather in paris right now? Also write a haiku about it.\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:06:11.084482], tool_use_agent:\u001b[0m\n",
      "\n",
      "The weather in Paris is currently 72 degrees and sunny. \n",
      "\n",
      "Here's a Haiku for you:\n",
      "\n",
      "Gentle sunlit streets,  \n",
      "Paris basks in golden light,  \n",
      "Seventy-two's grace.  \n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:06:11.084482], tool_use_agent:\u001b[0m\n",
      "\n",
      "The weather in Paris is currently 72 degrees and sunny. \n",
      "\n",
      "Here's a Haiku for you:\n",
      "\n",
      "Gentle sunlit streets,  \n",
      "Paris basks in golden light,  \n",
      "Seventy-two's grace.  \n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:06:11.084482], tool_use_agent:\u001b[0m\n",
      "\n",
      "The weather in Paris is currently 72 degrees and sunny. \n",
      "\n",
      "Here's a Haiku for you:\n",
      "\n",
      "Gentle sunlit streets,  \n",
      "Paris basks in golden light,  \n",
      "Seventy-two's grace.  \n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:06:11.086263], Termination:\u001b[0m\n",
      "\n",
      "Maximum number of messages 2 reached, current message count: 2\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:06:11.086263], Termination:\u001b[0m\n",
      "\n",
      "Maximum number of messages 2 reached, current message count: 2\n",
      "--------------------------------------------------------------------------- \n",
      "\u001b[91m[2024-11-02T22:06:11.086263], Termination:\u001b[0m\n",
      "\n",
      "Maximum number of messages 2 reached, current message count: 2"
     ]
    }
   ],
   "source": [
    "termination = MaxMessageTermination(max_messages=2)\n",
    "llm_team = SelectorGroupChat(\n",
    "    [tool_use_agent, writing_assistant_agent], model_client=model_client, termination_condition=termination\n",
    ")\n",
    "\n",
    "llm_team_result = await llm_team.run(\"What is the weather in paris right now? Also write a haiku about it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d40479-5584-4bd3-9f31-15045ebd4f03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
